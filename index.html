<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">    
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Zhenhua Tang Homepage</title>

    <!-- Le styles -->
    <link href="bootstrap.css" rel="stylesheet">
    <style type="text/css">
      body {
        padding-top: 20px;
        padding-bottom: 60px;
      }
	  
	  .foot-fixed-bottom {
 bottom: 0;
 display: block;
 left: 0;
 margin-bottom: 0;
 position: fixed;
 right: 0;
 z-index: 1030;
 background-color: rgba(130, 130, 130, 0.8);
}
.foot-fixed-bottom hr {
 border-image: none;
 border-style: solid none;
 border-width: 1px 0;
 margin: 0 0 5px;
 width: 100%;
}
.foot-fixed-bottom p {
 color: rgb(255, 255, 255);
 font-size: 14px;
 margin: 0 12px 15px;
}

      /* Custom container */
      .container {
        margin: 0 auto;
        max-width: 1000px;
      }
      .container > hr {
        margin: 60px 0;
      }

      /* Main marketing message and sign up button */
      .jumbotron {
        margin: 80px 0;
        text-align: center;
      }
      .jumbotron h1 {
        font-size: 100px;
        line-height: 1;
      }
      .jumbotron .lead {
        font-size: 24px;
        line-height: 1.25;
      }
      .jumbotron .btn {
        font-size: 21px;
        padding: 14px 24px;
      }

      /* Supporting marketing content */
      .marketing {
        margin: 60px 0;
      }
      .marketing p + h4 {
        margin-top: 28px;
      }


      /* Customize the navbar links to be fill the entire space of the .navbar */
      .navbar .navbar-inner {
        padding: 0;
      }
      .navbar .nav {
        margin: 0;
        display: table;
        width: 100%;
      }
      .navbar .nav li {
        display: table-cell;
        width: 1%;
        float: none;
      }
      .navbar .nav li a {
        font-weight: bold;
        text-align: center;
        border-left: 1px solid rgba(255,255,255,.75);
        border-right: 1px solid rgba(0,0,0,.1);
      }
      .navbar .nav li:first-child a {
        border-left: 0;
        border-radius: 3px 0 0 3px;
      }
      .navbar .nav li:last-child a {
        border-right: 0;
        border-radius: 0 3px 3px 0;
      }
    </style>
    <link href="bootstrap-responsive.css" rel="stylesheet">

    
  </head>

  <body>

      <div class="masthead">
        <h3 class="muted"></h3>
        <div class="navbar navbar-fixed-top">
          <div class="navbar-inner">
            <div class="container">
              <ul class="nav">
                <li><a href="#">Home</a></li>
                <li><a href="#bio">Short Bio</a></li>
                <!--<li><a href="#Download">Download</a></li>-->
                <li><a href="#Publication">Publication</a></li> 
		<li><a href="#Project">Project-科研项目</a></li>
                <li><a href="#Hometown">Tang's Travels-我的旅行</a></li>
              </ul>
            </div>
          </div>
        </div><!-- /.navbar -->
      </div>

      <div class="container">
	      <br><br>
		  <div class="bs-docs-grid ">
	 
	  	  <div class="media">
		    <a class="pull-left">
			    <img src="zhenhuat.jpg" height="100" width="150" class="media-object" >
			</a>
			<div class="media-body">			
			<h4>Zhenhua Tang (唐振华)</h4>
			<!--<h5>Ph.D student in Computer Science and Technology <a href="./cv.pdf">(CV)</a></h5>-->
	
                        <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=5Iop66sAAAAJ" >Google Scholar</a><br>

			Lab for Multimedia Computing <a href="http://data-science.ustc.edu.cn/">(多媒体计算实验室)</a><br>
			School of Computer and Information <a href="http://sds.ustc.edu.cn/">(计算机与信息学院 SDS)</a><br>			
			Hefei University of Technology<br>
      <br><br>
			<i>Email: zhenhuat AT foxmail.com</i>			
			 
		 </div></div>
		 
		 <a id= "bio"></a>
		 <hr>
		 <div class="row">	
		 <div class="span">
				<h4>Short Bio</h4>
       Zhenhua Tang is a Ph.D. student under the supervision of <a href="http://ci.hfut.edu.cn/2018/0819/c6404a168596/page.htm">Prof. Richang Hong</a>  at <a href="http://www.hfut.edu.cn/">Hefei University of Technology (HFUT)</a> in Anhui, China. He holds a B.E. degree from Hefei University of Technology and an M.E. degree from Shenzhen University, which he received in 2015 and 2020, respectively. His current research interests primarily focus on computer vision and multimedia data analysis, specifically in the areas of human pose estimation, motion synthesis, and AI choreography. He has authored papers that have been published in esteemed journals and conferences, including CVPR, TMM, TCSVT, PRL, ACML, and more.


				
		 </div>
		 </div>
		 <!--	
		 <a id= "Download"></a>
		 <hr>
		 <div class="row">	
		 <div class="span">
				<h4>Download</h4>
				<ul>
				<li><b><a
                    href="http://vireo.cs.cityu.edu.hk/vireoweb81"><u>VIREO-WEB81</u></a>
                    concept detectors, features and detection scores on
                    NUS-WIDE dataset</b> <br>
                    We are pleased to release 81 semantic concept detectors
                    trained on the NUS-WIDE training dataset, and their
                    detection scores on NUS-WIDE testing dataset. Global and
                    local features (BoW) are also available.</li> 
				</ul>
		 </div>
		 </div>
		 -->
		 <a id= "Publication"></a>
		 <hr>
		 <div class="row">	
		 <div class="span">
	<h4>Selected Publications</h4>
	
	<h5><i>Conference</i></h5>
	<ul>
		
		<h5><i>2023</i></h5>
		
		<li><b>Bi-directional Distribution Alignment for Transductive Zero-Shot Learning</b><a target="_blank"
                    href="https://arxiv.org/pdf/2303.08698.pdf"><img
                    border="0" src="./pdf.bmp" align="top"></a><a target="_blank"
		    href="https://github.com/Zhicaiwww/Bi-VAEGAN"> code</a><br>
                    Zhicai Wang, <i><b>Yanbin Hao*</b></i>, Tingting Mu, Ouxiang Li, Shuo Wang, Xiangnan He*, CVPR, 2023.
                    <br>
                    <br>
                 </li>
		
		<li><b>3D Human Pose Estimation with Spatio-Temporal Criss-cross Attention</b><a target="_blank"
                    href=""><img
                    border="0" src="./pdf.bmp" align="top"></a><a target="_blank"
		    href=""> code</a><br>
                    Zhenhua Tang, Zhaofan Qiu, <i><b>Yanbin Hao</b></i>, Richang Hong, Ting Yao, CVPR, 2023.
                    <br>
                    <br>
                 </li>
		
		<h5><i>2022</i></h5>
		
		<li><b>Group Contextualization for Video Recognition</b><a target="_blank"
                    href="https://arxiv.org/pdf/2203.09694.pdf"><img
                    border="0" src="./pdf.bmp" align="top"></a><a target="_blank"
		    href="https://github.com/haoyanbin918/Group-Contextualization"> code</a><br>
                    <i><b>Yanbin Hao</b></i>, Hao Zhang*, Chong-Wah Ngo, Xiangnan He, CVPR, Poster, 2022.
                    <br>
                    <br>
                 </li>
		
		<li><b>MF-GAN: Multi-conditional Fusion Generative Adversarial Network for Text-to-Image Synthesis</b><a target="_blank"
                    href="https://link.springer.com/chapter/10.1007/978-3-030-98358-1_4"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    Yuyan Yang, Xin Ni, <i><b>Yanbin Hao</b></i>, Chenyu Liu, Wenshan Wang, Yifeng Liu and Haiyong Xie, MMM, Oral (Hornorable Mention Award), 2022.
                    <br>
                    <br>
                 </li>
		
		<li><b>Unsupervised Video Hashing with Multi-granularity Contextualization and Multi-structure Preservation</b><a target="_blank"
                    href="http://staff.ustc.edu.cn/~hexn/papers/mm22-video-hashing.pdf"><img
                    border="0" src="./pdf.bmp" align="top"></a><a target="_blank"
		    href="https://github.com/haoyanbin918/MCMSH"> code</a><br>
                    <i><b>Yanbin Hao</b></i>, Jingru Duan, Hao Zhang*, Bin Zhu, Pengyuan Zhou and Xiangnan He, ACM MM, poster, 2022.
                    <br>
                    <br>
                 </li>
		
		<li><b>Long-term Leap Attention, Short-term Periodic Shift for Video Classification</b><a target="_blank"
                    href="https://arxiv.org/pdf/2207.05526.pdf"><img
                    border="0" src="./pdf.bmp" align="top"></a><a target="_blank"
		    href="https://github.com/VideoNetworks/LAPS-transformer"> code</a><br>
                    Hao Zhang, Lechao Cheng, <i><b>Yanbin Hao*</b></i> and Chong-Wah Ngo, ACM MM, oral, 2022.
                    <br>
                    <br>
                 </li>
		
		<li><b>Parameterization of Cross-Token Relations with Relative Positional Encoding for Vision MLP</b><a target="_blank"
                    href="https://arxiv.org/pdf/2207.07284.pdf"><img
                    border="0" src="./pdf.bmp" align="top"></a><a target="_blank"
		    href="https://github.com/Zhicaiwww/PosMLP"> code</a><br>
                    Zhicai Wang, <i><b>Yanbin Hao*</b></i>, Xingyu Gao*, Hao Zhang, Shuo Wang, Tingting Mu and Xiangnan He, ACM MM, poster, 2022.
                    <br>
                    <br>
                 </li>
		
		<li><b>Hierarchical Hourglass Convolutional Network for Efficient Video Classification</b><a target="_blank"
                    href="http://staff.ustc.edu.cn/~hexn/papers/mm22-hourglass-cnn-video.pdf"><img
                    border="0" src="./pdf.bmp" align="top"></a><a target="_blank"
		    href="https://github.com/ty-97/H2CN"> code</a><br>
                    Yi Tan, <i><b>Yanbin Hao*</b></i>, Hao Zhang, Shuo Wang and Xiangnan He*, ACM MM, poster, 2022.
                    <br>
                    <br>
                 </li>
		
		<li><b>Multi-directional Knowledge Transfer for Few-Shot Learning</b><a target="_blank"
                    href="http://staff.ustc.edu.cn/~hexn/papers/mm22-knowledge-few-shot.pdf"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    Shuo Wang, Xinyu Zhang, <i><b>Yanbin Hao</b></i>, Chengbing Wang and Xiangnan He*, ACM MM, poster, 2022.
                    <br>
                    <br>
                 </li>
		
	        <h5><i>2021</i></h5>
				
		<li><b>Token Shift Transformer for Video Classification</b><a target="_blank"
                    href="https://dl.acm.org/doi/abs/10.1145/3474085.3475272"><img
                    border="0" src="./pdf.bmp" align="top"></a><a target="_blank"
		    href="https://github.com/VideoNetworks/TokShift-Transformer"> code</a><br>
                    Hao Zhang, <i><b>Yanbin Hao*</b></i>, Chong-Wah Ngo, ACM Multimedia (MM), Poster, 2021.
                    <br>
                    <br>
                 </li>
			 
			 <li><b>Selective Dependency Aggregation for Action Classification</b><a target="_blank"
                    href="https://dl.acm.org/doi/abs/10.1145/3474085.3475218"><img
                    border="0" src="./pdf.bmp" align="top"></a><a target="_blank"
		    href="https://github.com/ty-97/SDA"> code</a><br>
                    Yi Tan, <i><b>Yanbin Hao*</b></i>, Xiangnan He, Yinwei Wei, Xun Yang, ACM Multimedia (MM), Poster, 2021.
                    <br>
                    <br>
                 </li>
		
			<li><b>Motion Prediction Using Trajectory Cues</b><a target="_blank"
                    href="https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Motion_Prediction_Using_Trajectory_Cues_ICCV_2021_paper.html"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    Zhenguang Liu, Pengxiang Su, Shuang Wu, Xuanjing Shen, Haipeng Chen, <i><b>Yanbin Hao</b></i>, Meng Wang, ICCV, 2021.
                    <br>
                    <br>
                 </li>
					
		<li><b>NASTER: Non-local Attentional Scene Text Recognizer</b><a target="_blank"
                    href="https://dl.acm.org/doi/abs/10.1145/3460426.3463623"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    Lei Wu, Xueliang Liu, <i><b>Yanbin Hao</b></i>, Yunjie Ma, Richang Hong, ICMR, 2021.
                    <br>
                    <br>
                 </li>
					
		<li><b>Aggregated Multi-GANs for Controlled 3D Human Motion Prediction</b><a target="_blank"
                    href=""><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    Z. Liu, K. Lyu, S. Wu, H. Chen, <i><b>Y. Hao</b></i>, S. Ji, Association for the Advancement of Artificial Intelligence (AAAI), 2021.
                    <br>
                    <br>
                 </li>
		
			<h5><i>2020&before</i></h5>		
				<li><b>Compact Bilinear Augmented Query Structured Attention for Sport Highlights Classification</b><a target="_blank"
                    href="https://dl.acm.org/doi/10.1145/3394171.3413595"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    <i><b>Y. Hao</b></i>, H. Zhang*, C.-W. Ngo, Q. Liu, X. Hu, ACM Multimedia (MM), Oral, 2020.
                    <br>
                    <br>
                 </li>


				<li><b>Person-level Action Recognition in Complex Events via TSD-TSM networks</b><a target="_blank"
                    href=""><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    <i><b>Y. Hao</b></i>, Z.-N. Liu, H. Zhang*, B. Zhu, J. Chen, Y. Jiang, C.-W. Ngo, ACM Multimedia Workshop(MMW), 2020. <br>Rank 3rd in HiEve2020 Grand Challenge <a href="http://humaninevents.org/final_ranking_acm2020.html">(Track-4）</a>
                    <br>
                    <br>
                 </li>

				<li><b>R2GAN: Cross-modal recipe retrieval with generative adversarial network</b><a target="_blank"
                    href=""><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    B. Zhu, C.-W. Ngo, J. Chen, and <i><b>Y. Hao</b></i>, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019.
                    <br>
                    <br>
                 </li>


				<li><b>Cross-sentence Pre-trained model for Interactive QA matching</b><a target="_blank"
                    href="https://www.aclweb.org/anthology/2020.lrec-1.666/"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    J. Wu and <i><b>Y. Hao</b></i>, Proceedings of The 12th Language Resources and Evaluation Conference, 2020.
                    <br>
                    <br>
                 </li>
				
		</ul>
	<h5><i>Journal</i></h5>
	<ul>
		<h5><i>2023</i></h5>
		
		<li><b>MLP-JCG: Multi-Layer Perceptron with Joint-Coordinate Gating for Efficient 3D Human Pose Estimation</b> <a target="_blank"
                    href="https://ieeexplore.ieee.org/abstract/document/10029937/"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
		    Zhenhua Tang, Jia Li*, <i><b>Yanbin Hao</b></i>, Richang Hong*, IEEE Transactions on Multimedia (TMM), 2023.
                    <br><br>
                 </li>
		
		<li><b>Boosting Hyperspectral Image Classification with Dual Hierarchical Learning</b> <a target="_blank"
                    href="https://dl.acm.org/doi/abs/10.1145/3522713"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
		    Shuo Wang, Huixia Ben, <i><b>Yanbin Hao</b></i>, Xiangnan He, Meng Wang, ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 2022.
                    <br><br>
                 </li>
		
		<h5><i>2022</i></h5>
		
		<li><b>Spatio-Temporal Collaborative Module for Efficient Action Recognition</b> <a target="_blank"
                    href="https://ieeexplore.ieee.org/abstract/document/9952204/"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
		    <i><b>Yanbin Hao</b></i>, Shuo Wang, Yi Tan, Xiangnan He, Zhenguang Liu, Meng Wang, IEEE Transactions on Image Processing (TIP), 2022.
                    <br><br>
                 </li>
		
		<li><b>Attention in Attention: Modeling Context Correlation for Efficient Video Classification</b> <a target="_blank"
                    href="https://ieeexplore.ieee.org/abstract/document/9762292"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
		    <i><b>Yanbin Hao</b></i>, Shuo Wang, Pei Cao, Xinjian Gao, Tong Xu, Jinmeng Wu, Xiangnan He, IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2022.
                    <br><br>
                 </li>
		
		
	<h5><i>2021</i></h5>
					
	<li><b>Learning to Match Anchor-Target Video Pairs with Dual Attentional Holographic Networks</b> <a target="_blank"
                    href="https://ieeexplore.ieee.org/abstract/document/9547825/"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    <i><b>Yanbin Hao*</b></i>, Chong-Wah Ngo, Bin Zhu, IEEE Trans on Image Processing (TIP), 2021.
                    <br><br>
                 </li>
					
	<li><b>Auxiliary Diagnosis for COVID-19 with Deep Transfer Learning</b> <a target="_blank"
                    href="https://link.springer.com/article/10.1007/s10278-021-00431-8"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    Hongtao Chen, Shuanshuan Guo, <i><b>Yanbin Hao*</b></i>, Yijie Fang, Zhaoxiong Fang, Wenhao Wu, Zhigang Liu, Shaolin Li*, Journal of Digital Imaging, 2021.
                    <br><br>
                 </li>
					
	<li><b>Space-Time Separate Modeling for Efficient Video Classification</b> <a target="_blank"
                    href="https://iopscience.iop.org/article/10.1088/1742-6596/2024/1/012063/meta"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    Pei Cao, Shuo Wang*, Jinmeng Wu, <i><b>Yanbin Hao</b></i>, Journal of Physics: Conference Series, 2021.
                    <br><br>
                 </li>
					
	<h5><i>2020&Before</i></h5>

        <li><b>Cross-domain sentiment encoding through stochastic word embedding</b> <a target="_blank"
                    href="https://ieeexplore.ieee.org/abstract/document/8700271"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    <i><b>Y. Hao</b></i>, T. Mu, R. Hong, M. Wang and J. Y. Goulermas, IEEE Trans on Knowledge and Data Engineering (TKDE), 2020.
                    <br><br>
                 </li>

				<li><b>Neighbourhood structure preserving cross-modal embedding for video hyperlinking</b> <a target="_blank"
                    href="https://ieeexplore.ieee.org/abstract/document/8736841"><img
                    border="0" src="./pdf.bmp" align="top"></a><a target="_blank"
                    href="https://github.com/haoyanbincityu/G-MmDAE"> code</a><br>
                    <i><b>Y. Hao</b></i>, C.-W. Ngo and B. Huet, IEEE Trans on Multimedia (TMM), 2019.
                    <br><br>
                 </li>

				<li><b>Unsupervised t-distributed video hashing and its deep hashing extension</b><a target="_blank"
                    href="https://ieeexplore.ieee.org/abstract/document/8003492"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    <i><b>Y. Hao</b></i>, T. Mu, J. Y. Goulermas, J. Jiang, R. Hong and M. Wang, IEEE Trans on Image Processing (TIP), 2017.
                    <br><br>
                 </li>

				<li><b>Stochastic multiview hashing for large-scale near-duplicate video retrieval</b> <a target="_blank"
                    href="https://ieeexplore.ieee.org/abstract/document/7568987"><img
                    border="0" src="./pdf.bmp" align="top"></a><a target="_blank"
                    href="https://github.com/haoyanbincityu/SMVH_matlab"> code</a><br>
                    <i><b>Y. Hao</b></i>, T. Mu, R. Hong, M. Wang, N. An and J. Y. Goulermas, IEEE Trans on Multimedia (TMM), 2016.
                    <br><br>
                 </li>

        <li><b>3D human pose estimation via human structure-aware fully connected network</b> <a target="_blank"
                    href="https://www.sciencedirect.com/science/article/pii/S016786551830432X"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    X. Zhang, Z. Tang, J. Hou and <i><b>Y. Hao</b></i>, Pattern Recognition Letters, 2019.
                    <br><br>
                 </li>
	</ul>
		 </div>
		 </div>
	  
     <a id= "Project"></a>
     <hr>
     <div class="row">	
     <div class="span">
     <h4>主持的科研项目</h4>
	     <li><b>面向大规模事件检索的高效紧凑视频表征方法研究</b>,国家自然科学青年基金，2021-2024年。
                    <br><br>
                 </li>
	     <li><b>基于因果与认知推理的用户行为建模关键技术研究</b>,国家自然科学联合基金重点项目，2021-2025年。
                    <br><br>
                 </li>
	     <li><b>人机协同的稿件质量评价体系</b>,科技部重点研发计划，2020-2023年。
                    <br><br>
                 </li>
	     <li><b>社交媒体热点事件知识图谱构建</b>,安徽省高校协同创新项目，2021-2023年。
                    <br><br>
                 </li>
    </div>
     </div>

     <a id= "Hometown"></a>
     <hr>
     <div class="row">  
     <div class="span">
        <h4>Hao's Hometown, 我美丽的家乡</h4>
        <ul>
        <li>He was born in Tangshan, Hebei, China. His hometown is at Mi Cheng Zhuang (a small and perfectly peaceful village), <a href="https://baike.baidu.com/item/%E8%BF%81%E8%A5%BF%E5%8E%BF/4703683?fromtitle=%E8%BF%81%E8%A5%BF&fromid=2322453&fr=aladdin"><u>Qianxi</u></a> (a north county in China mainland, the hometown of Chinese chestnut (中国板栗之乡)), <a href="https://baike.baidu.com/item/%E5%94%90%E5%B1%B1/7529?fr=aladdin"><u>Tangshan</u></a> (the north city famous for porcelains (中国北方瓷都)). He studied in <u>Michengzhuang Central Primary School (米城庄中心小学)</u>, <u>Xinzhuangzi Junior Middle School (新庄子乡中学)</u> and <a href="https://baike.baidu.com/item/%E8%BF%81%E8%A5%BF%E5%8E%BF%E7%AC%AC%E4%B8%80%E4%B8%AD%E5%AD%A6/11051443?fr=aladdin"><u>Qianxi NO.1 Middle School (迁西县第一中学)</u></a> during primary and secondary school time.
        </li> 
        </ul>
     </div>
     </div>
     <div class="home_pictures">
      <div class="scene">
        <img src="hometownpic/banli1.jpg" width="300" height="300" title="大山中的板栗", alt="大山中的板栗">
        <img src="hometownpic/chun_tianye.jpg" width="300" height="300" title="春天的田野", alt="春天的田野">
        <img src="hometownpic/xia_heliu.jpg" width="300" height="300" title="夏天的小河", alt="夏天的小河">
	<img src="hometownpic/lihua.jpg" width="300" height="300" title="梨花山坡", alt="梨花山坡">
        <img src="hometownpic/fangzi.jpg" width="300" height="300" title="大山深处的村庄", alt="大山深处的村庄">
	<img src="hometownpic/dong_dashan.jpg" width="300" height="300" title="冬天的大山", alt="冬天的大山">
        
      </div>
       
     </div>

		 <hr>
		  
      </div></div> <!-- /container -->
      <div class="foot-fixed-bottom">
	  	      <p align = "right"><a href= "http://twitter.github.com/bootstrap/"><u><font color="#000000">Proudly powered by Bootstrap</font></u></a></p>
      </div>
     



    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/js/jquery.js"></script>
    <script src="../assets/js/bootstrap-transition.js"></script>
    <script src="../assets/js/bootstrap-alert.js"></script>
    <script src="../assets/js/bootstrap-modal.js"></script>
    <script src="../assets/js/bootstrap-dropdown.js"></script>
    <script src="../assets/js/bootstrap-scrollspy.js"></script>
    <script src="../assets/js/bootstrap-tab.js"></script>
    <script src="../assets/js/bootstrap-tooltip.js"></script>
    <script src="../assets/js/bootstrap-popover.js"></script>
    <script src="../assets/js/bootstrap-button.js"></script>
    <script src="../assets/js/bootstrap-collapse.js"></script>
    <script src="../assets/js/bootstrap-carousel.js"></script>
    <script src="../assets/js/bootstrap-typeahead.js"></script>

  </body>
</html>
